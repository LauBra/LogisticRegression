---
title: '(1b) Fitting a logistic regression model - Python'
format: html
execute:
  engine: knitr
---

```{r}
library(reticulate)

# one-off setup (if you haven't done it yet)
# install_miniconda()

##conda_create(
##  envname = "hds-python",
##  python_version = "3.11",
##  packages = c("numpy", "pandas", "matplotlib", "seaborn", "scikit-learn")
##)

use_condaenv("hds-python", required = TRUE)
#py_config()

#conda_install("hds-python", c("jupyter", "plotly"))
```


```{python}
# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
```

```{python}
# Load the Pima Indians Diabetes dataset
data = fetch_openml(name="diabetes", version=1, as_frame=True)
PimaIndiansDiabetes = data.frame


```

We have some different names (plas is glucose in R), but same idea.

```{python}
# Select relevant features and target variable
PimaIndiansDiabetes = PimaIndiansDiabetes[["plas", "class", "mass", "age"]]
```

```{python}
# Define predictor (X) and target (y) variables
X = PimaIndiansDiabetes[["plas"]]
y = PimaIndiansDiabetes["class"]
```

```{python}
# Fit a logistic regression model using sklearn
logistic_model = LogisticRegression()
logistic_model.fit(X, y)
```

```{python}
# Display model coefficients
intercept = logistic_model.intercept_[0]
slope = logistic_model.coef_[0][0]
print(f"Intercept: {intercept}, Slope: {slope}")
```

```{python}
# Predict probabilities
PimaIndiansDiabetes["predicted_probability"] = logistic_model.predict_proba(X)[:, 1]
```

```{python}
PimaIndiansDiabetes.head()
```

```{python}
# Visualise predictions
plt.figure(figsize=(8, 6))
plt.scatter(PimaIndiansDiabetes["plas"], PimaIndiansDiabetes["class"], alpha=0.5, label="Actual")
plt.scatter(PimaIndiansDiabetes["plas"], PimaIndiansDiabetes["predicted_probability"], color="red", alpha=0.5, label="Predicted")
plt.plot(
    np.sort(PimaIndiansDiabetes["plas"]),
    np.sort(logistic_model.predict_proba(X)[:, 1]),
    color="blue",
    label="Logistic Regression Curve"
)
plt.xlabel("Glucose")
plt.ylabel("Diabetes (0 or 1)")
plt.title("Logistic Regression: Glucose vs Diabetes")
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

------------------------------------------------------------------------

Now include more predictors: "plas" and "age"

```{python}
# Fit logistic regression with multiple predictors
X_multi = PimaIndiansDiabetes[["plas", "age"]]
logistic_model_two = LogisticRegression()
logistic_model_two.fit(X_multi, y)
```

```{python}
# Display model coefficients
intercept = logistic_model_two.intercept_[0]
slope = logistic_model_two.coef_[0][0]
print(f"Intercept: {intercept}, Slope: {slope}")
```

```{python}
# Predict probabilities for the multi-feature model
PimaIndiansDiabetes["predicted_probability_two"] = logistic_model_two.predict_proba(X_multi)[:, 1]
```

Visualize the probabilities

```{python}
PimaIndiansDiabetes.head()
```

------------------------------------------------------------------------

Add mass to the modeling too (so in total three predictors, one outcome variable), how do the predictions change?

```{python}

```
